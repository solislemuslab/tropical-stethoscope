{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification_with_augmentation.ipynb","provenance":[],"collapsed_sections":["CO3wnIYi4xM8"],"toc_visible":true,"authorship_tag":"ABX9TyON2ma0uHC4kpORNbBc2HvZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"E7xnoDEz8R-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610816873993,"user_tz":360,"elapsed":6736,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}},"outputId":"bf38f019-93b6-4fec-8b65-f13708035f53"},"source":["%tensorflow_version 1.x\n","import os\n","import h5py\n","import random\n","import numpy as np\n","import pandas as pd\n","import keras\n","from keras.optimizers import Adam, SGD\n","from keras.applications import VGG19\n","from keras.utils import to_categorical\n","from keras.models import Model, load_model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.layers import Dense, Activation, Flatten, Dropout, Input, concatenate\n","import cv2\n","import csv\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3NeB0pNE8cAe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610816929879,"user_tz":360,"elapsed":26974,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}},"outputId":"25478b22-33bf-4f6e-ac6d-a52e41662674"},"source":["drive.mount('/content/drive')\n","os.chdir('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IsHf2yAB8gvB"},"source":["# Read the dataset"]},{"cell_type":"code","metadata":{"id":"GYSJE0ph8dtd"},"source":["f =  h5py.File('My Drive/Stethoscope/whole_data_1110.hdf5', \"r\")\n","\n","specs_h5 = np.array(f[\"specs\"]).astype(\"float32\")\n","sonotypes_h5 = np.array(f[\"sonotypes\"]).astype(\"float32\")\n","times_h5 = np.array(f[\"times\"]).astype(\"float32\")\n","freqs_h5 = np.array(f[\"freqs\"]).astype(\"float32\")\n","groups_h5 = np.array(f[\"groups\"])\n","selection_h5 = np.array(f[\"selections\"])\n","\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-1m0t2Y8m2w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610816971944,"user_tz":360,"elapsed":35080,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}},"outputId":"5c367cd1-3b30-4555-f3f1-fd3ce152dcde"},"source":["# append x_times an x_freqs to be auxiliary_input\n","aux_input_h5 = np.append(times_h5,freqs_h5, axis = 1)\n","\n","print(aux_input_h5.shape)\n","print(aux_input_h5[10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrILaIAW8nZp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610816971945,"user_tz":360,"elapsed":34747,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}},"outputId":"7c10ff07-edcc-4258-ed2c-b372f7589ca3"},"source":["# create the dictionary for sonotypes and groups\n","sono2group = dict(zip(sonotypes_h5,groups_h5))\n","\n","# get the data for top k sonotypes\n","s_unique, s_freq = np.unique(sonotypes_h5,return_counts=True)\n","s_freq_order = np.argsort(s_freq)[::-1]\n","s_freq_desc = s_freq[s_freq_order]\n","\n","print(len(s_unique))\n","print(s_unique[s_freq_order][:20])\n","print(s_freq_desc[:20])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VSf-dXWsHbV"},"source":["# Normalization"]},{"cell_type":"code","metadata":{"id":"8vdu4viHsDyH"},"source":["# normalization„ÄÅ the data\n","def normalize(specs):\n","  return_specs = []\n","  for i in range(len(specs)):\n","    cur_spec = np.copy(specs[i])\n","    s_min = np.amin(cur_spec)\n","    s_max = np.amax(cur_spec)\n","    # specs[i] = (cur_spec - s_min)/(s_max - s_min) * 255\n","    return_specs.append( (cur_spec - s_min)/(s_max - s_min) )\n","    # return_specs.append( np.log( (cur_spec - s_min)/(s_max - s_min) ) )\n","\n","  return return_specs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Divm4kJd-ufK"},"source":["# Augmentation Methods"]},{"cell_type":"code","metadata":{"id":"jeHY3yeO-0FX"},"source":["# choppint methods, each return a spec\n","# time chop\n","def time_chop(spec, rand_start):\n","  time_chopped_spec = np.copy(spec)\n","  time_chopped_spec[:,224 - rand_start:,:] = 0\n","\n","  return [time_chopped_spec]\n","\n","# freq chop\n","def freq_chop(spec, rand_start):\n","  freq_chopped_spec = np.copy(spec)\n","  freq_chopped_spec[0:rand_start,:,:] = 0\n","\n","  return [freq_chopped_spec]\n","\n","# four side chop\n","def four_chop(spec, rand_start):\n","  four_chopped_spec = np.copy(spec)\n","  four_chopped_spec[0 : rand_start,:,:] = 0  # top\n","  four_chopped_spec[:,224 - rand_start:,:] = 0  # right\n","  four_chopped_spec[224 - rand_start:,:,:] = 0  # bottom\n","  four_chopped_spec[:, 0 : rand_start ,:] = 0  # left\n","\n","  return [four_chopped_spec]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2s1Hlo6q9-BC"},"source":["# add noises methods, return a list of spec\n","def add_noises(spec):\n","  # add noise from light rian -2, rain -3, heavy rain -4, thunder -5, aircraft -6, chainsaw -7, and car/truck -8\n","  return_specs = []\n","  noise_sonos = [-2, -3, -4, -5,-6,-7,-8]\n","\n","  for i in range(len(noise_sonos)):\n","    noises_index = np.argwhere(sonotypes_h5 == noise_sonos[i]).flatten()\n","    noises = specs_h5[noises_index]\n","    index = random.randint(0, len(noises) - 1)\n","    noise = normalize(np.array(noises[index]) / 3)\n","\n","    return_specs.append(np.add(normalize([spec])[0], noise))\n","\n","  return return_specs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3lLYDZU_VAJ"},"source":["# transalate up and down, return two spec\n","# frequency ranges too large[1333.532 2565.584] [3084.02  3890.613]\n","def translate(spec, roll_start):\n","  return_specs = []\n","  return_specs.append(np.roll(spec, -roll_start, axis = 0))\n","  return_specs.append(np.roll(spec, roll_start, axis = 0))\n","\n","  return return_specs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMRDhokq_Wg9"},"source":["# widen and squeezing\n","def widen(spec, widen_index):\n","  return_specs = []\n","\n","  widen_time_spec=cv2.resize(spec.astype('float32'),(224 + widen_index,224))\n","  widen_freq_spec=cv2.resize(spec.astype('float32'),(224,224 + widen_index))\n","\n","  return_specs.append(widen_time_spec[:,widen_index // 2: -widen_index // 2,:])\n","  return_specs.append(widen_freq_spec[widen_index // 2: -widen_index // 2,:,:])\n","\n","  return return_specs\n","\n","def squeeze(spec, squeeze_index):\n","  squeezed=cv2.resize(spec.astype('float32'),(224 - squeeze_index,224 - squeeze_index))\n","  squeeze_spec = np.zeros([224, 224, 3])\n","  squeeze_spec[squeeze_index//2 : - squeeze_index //2,squeeze_index//2 : - squeeze_index //2, :] = squeezed\n","\n","  return [squeeze_spec]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfJQnb19kqGn"},"source":["def augment(specs, aux_input, sonotypes, aug_num, augment_range = 0.1):\n","  # augment_range = 0.1\n","  augment_specs_func = []\n","  augment_aux_func = []\n","  augment_sono_func = []\n","\n","  # print(len(aux_input))\n","  for i in range(len(specs)):\n","    # generate random index array for augmentation\n","    indices = np.arange(int(224 * augment_range / 3 * 2) , int(224 * augment_range))\n","    np.random.shuffle(indices)\n","    indices = indices[:aug_num]\n","    \n","    # augment each spec and add to list\n","    cur_spec = np.copy(specs[i])\n","    # add itself to the list\n","    if (len(augment_specs_func)):\n","      augment_specs_func = np.append(augment_specs_func, [cur_spec], axis = 0)\n","    else:\n","      augment_specs_func.append(cur_spec)\n","\n","    for index in indices:\n","      # print(index)\n","      # chop\n","      augment_specs_func = np.append(augment_specs_func, time_chop( np.copy(cur_spec), index), axis = 0)\n","      augment_specs_func = np.append(augment_specs_func, freq_chop( np.copy(cur_spec), index), axis = 0)\n","      augment_specs_func = np.append(augment_specs_func, four_chop( np.copy(cur_spec), index), axis = 0)\n","\n","      # widen + squeeze\n","      augment_specs_func = np.append(augment_specs_func, squeeze( np.copy(cur_spec), index), axis = 0)\n","      augment_specs_func = np.append(augment_specs_func, widen( np.copy(cur_spec), index), axis = 0)\n","      \n","      # noise\n","      augment_specs_func = np.append(augment_specs_func, add_noises(np.copy(cur_spec)), axis = 0)\n","\n","      # translate\n","      augment_specs_func = np.append(augment_specs_func, translate(np.copy(cur_spec), index), axis = 0)\n","\n","    # total 1 + 15 * aug_num augmented, repeat the sono and aux\n","    if (len(augment_aux_func)):\n","      augment_aux_func = np.append(augment_aux_func, np.repeat([aux_input[i]], 1 + 15 * aug_num, axis = 0), axis= 0)\n","    else:\n","      augment_aux_func = np.repeat([aux_input[i]], 1 + 15 * aug_num, axis = 0)\n","\n","    augment_sono_func = np.append(augment_sono_func, np.repeat(sonotypes[i], 1 + 15 * aug_num), axis= 0)\n","\n","  return augment_specs_func, augment_aux_func, augment_sono_func"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R86P76r0_xlX"},"source":["# Get data, Augment, Classify"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["groupUsed = b'b' # use bird for now\n","typeUsed = []\n","min_num = 49\n","# Use a specific group for here\n","typeUsed=[52.0, 86.0, 175.0]\n","print(typeUsed)\n","print(min_num)\n","\n","specs = []\n","aux_input = []\n","sonotypes = []\n","selections = []\n","spec_test = []\n","aux_test = []\n","y_test = []\n","spec_val = []\n","aux_val = []\n","y_val = []\n","\n","for i in range(len(typeUsed)):\n","  # get index of the current type of spec\n","  cur_index = np.argwhere(sonotypes_h5 == typeUsed[i]).flatten()\n","  # randomly choose index in b \n","  # to ensure we have same number of type b and i\n","  random.shuffle(cur_index)\n","  cur_index_resized = cur_index[:int(min_num * 0.8)]\n","  test_index = cur_index[int(min_num * 0.8): int(min_num * 0.9)]\n","  val_index = cur_index[int(min_num * 0.9): min_num]\n","\n","  if len(specs):\n","    specs = np.append(specs, specs_h5[cur_index_resized], axis = 0)\n","  else:\n","    specs = specs_h5[cur_index_resized]\n","\n","  if len(aux_input):\n","    aux_input = np.append(aux_input, aux_input_h5[cur_index_resized], axis= 0)\n","  else:\n","    aux_input = aux_input_h5[cur_index_resized]\n","  \n","  if len(sonotypes):\n","    sonotypes = np.append(sonotypes, np.repeat(i, int(min_num * 0.8)))\n","  else:\n","    sonotypes = np.repeat(i, int(min_num * 0.8))\n","\n","  if len(selections):\n","    selections = np.append(selections, selection_h5[cur_index_resized])\n","  else:\n","    selections = selection_h5[cur_index_resized]\n","\n","  if len(spec_test):\n","    spec_test = np.append(spec_test, specs_h5[test_index], axis = 0)\n","  else:\n","    spec_test = specs_h5[test_index]\n","\n","  if len(aux_test):\n","    aux_test = np.append(aux_test, aux_input_h5[test_index], axis = 0)\n","  else:\n","    aux_test = aux_input_h5[test_index]\n","\n","  if len(spec_val):\n","    spec_val = np.append(spec_val, specs_h5[val_index], axis = 0)\n","  else:\n","    spec_val = specs_h5[val_index]\n","\n","  if len(aux_val):\n","    aux_val = np.append(aux_val, aux_input_h5[val_index], axis = 0)\n","  else:\n","    aux_val = aux_input_h5[val_index]\n","\n","  if len(y_test):\n","    y_test = np.append(y_test, np.repeat(i, len(test_index)))\n","  else:\n","    y_test = np.repeat(i, len(test_index))\n","\n","  if len(y_val):\n","    y_val = np.append(y_val, np.repeat(i, len(val_index)))\n","  else:\n","    y_val = np.repeat(i, len(val_index)) \n","\n","x_test = [spec_test, aux_test]\n","x_val = [spec_val, aux_val]\n","\n","specs_keep = np.copy(specs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["config = dict(\n","    dropout = 0.5,\n","    hidden = 1024,\n","    learn_rate = 0.00001,\n","    epochs = 30,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_finetune_model(base_model, dropouts, fc_layers, num_classes):\n","    for layer in base_model.layers:\n","       layer.trainable = False\n","\n","    x = base_model.output\n","    x = Flatten()(x)\n","\n","    # add input layer\n","    auxiliary_input = Input(shape=(4,), name='aux_input')\n","    x = concatenate([x, auxiliary_input])\n","\n","    for fc, drop in zip(fc_layers, dropouts):\n","        x = Dense(fc, activation='relu')(x) \n","        x = Dropout(drop)(x)\n","\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","\n","    finetune_model = Model(inputs=[base_model.input,auxiliary_input], outputs=predictions)\n","    # finetune_model = Model(inputs=base_model.input, outputs=predictions)\n","\n","    return finetune_model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class TestCallback(keras.callbacks.Callback):\n","    def __init__(self, test_data):\n","        self.test_data = test_data\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        x, y = self.test_data\n","        loss, acc = self.model.evaluate(x, y, verbose=0)\n","        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n","\n","        # stop training if training \n","        # accuracy =r logs[\"val_accuracy\"]\n","        if acc >= 1:\n","            self.model.stop_training = True "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# generator functiion for fit_generator\n","def gen(specs, aux_input, sonotypes):\n","  while 1:\n","    # shuffle data\n","    indices = np.arange(len(sonotypes))\n","    np.random.shuffle(indices)\n","    # # use 30 of all data per epoch\n","    step_len = 4\n","\n","    for i in range(len(specs) // step_len):\n","      step_min = i * step_len\n","      step_max = min( (i + 1) * step_len, len(specs) )\n","      \n","      augment_specs, augment_aux, augment_sono =  augment(specs[indices][step_min: step_max], aux_input[indices][step_min: step_max], sonotypes[indices][step_min: step_max], 1)\n","\n","      augment_specs_normal = normalize(augment_specs)\n","      cat_y_train = to_categorical(augment_sono, num_classes= len(typeUsed))\n","      yield {'input_1': np.array([augment_specs_normal])[0], 'aux_input': np.array([augment_aux])[0]}, np.array([cat_y_train])[0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model with augmentation\n","model = None\n","keras.backend.clear_session()\n","model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n","model = build_finetune_model(model, \n","                             [config[\"dropout\"], config[\"dropout\"]], \n","                             [config[\"hidden\"], config[\"hidden\"]], \n","                             len(typeUsed))\n","\n","filepath_loss = 'My Drive/Stethoscope/model_loss.hdf5'\n","filepath_acc = 'My Drive/Stethoscope/model_acc.hdf5'\n","\n","# remove model before\n","if os.path.exists(filepath_loss):\n","  os.remove(filepath_loss)\n","if os.path.exists(filepath_acc):\n","  os.remove(filepath_acc)\n","\n","# earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","checkpoint_acc = ModelCheckpoint(filepath_acc, monitor='val_accuracy', mode='auto', verbose=1, save_best_only=True, save_weights_only=False, period=1)\n","checkpoint_loss = ModelCheckpoint(filepath_loss, monitor='val_loss', mode='auto', verbose=1, save_best_only=True, save_weights_only=False, period=1)\n","\n","opt = Adam(lr=config[\"learn_rate\"])\n","\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","history = model.fit_generator(gen(specs[indices_train], aux_input[indices_train], sonotypes[indices_train]),\n","                    steps_per_epoch=len(specs[indices_train]) // 4, epochs = 200, validation_data = (x_val, cat_y_val), callbacks=[checkpoint_loss, checkpoint_acc, TestCallback((x_test, cat_y_test))])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model w/o augmentation\n","model = None\n","keras.backend.clear_session()\n","model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n","model = build_finetune_model(model, \n","                             [config[\"dropout\"], config[\"dropout\"]], \n","                             [config[\"hidden\"], config[\"hidden\"]], \n","                             len(typeUsed))\n","\n","filepath = 'My Drive/Stethoscope/model_group.hdf5'\n","\n","earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","\n","opt = Adam(lr=config[\"learn_rate\"])\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","cat_y_train = to_categorical(sonotypes[indices_train], num_classes= len(typeUsed))\n","history = model.fit(x=[specs[indices_train], aux_input[indices_train]], y=cat_y_train, validation_data=(x_val, cat_y_val), epochs=300, verbose = 2, callbacks = [checkpoint, TestCallback((x_test, cat_y_test))])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# test for the model with lowest val loss\n","model = None\n","keras.backend.clear_session()\n","model = load_model (filepath_loss)\n","# evaluation\n","results = model.evaluate( x= x_test, y=cat_y_test)\n","print(\"best loss test loss, test acc:\", results)"]},{"cell_type":"markdown","metadata":{"id":"TXJk9Ez1S3hY"},"source":["# Repeat and generate data\n","Experiement for classification between random 6 sonotypes"]},{"cell_type":"code","metadata":{"id":"Qh7j8i1KsUlg"},"source":["# get data\n","def get_samples(numUsed):\n","  # get groups, augment each to 250 samples\n","  aug_goal = 250\n","  type_index = np.argwhere((s_freq_desc >= 3) & (s_unique[s_freq_order] > 0)).flatten()\n","  random.shuffle(type_index)\n","  type_index = np.sort(type_index[:numUsed])\n","  max_num = s_freq_desc[np.min(type_index)]\n","  typeUsed = s_unique[s_freq_order][type_index]\n","\n","  print(\"type index:\", type_index)\n","  print(\"type used: \", typeUsed)\n","  print(\"max num: \",max_num)\n","\n","  specs = []\n","  aux_input = []\n","  sonotypes = []\n","  spec_test = []\n","  aux_test = []\n","  y_test = []\n","  spec_val = []\n","  aux_val = []\n","  y_val = []\n","  sizes = []\n","\n","  for i in range(len(typeUsed)):\n","    # get index of the current type of spec\n","    cur_index = np.argwhere(sonotypes_h5 == typeUsed[i]).flatten()\n","    random.shuffle(cur_index)\n","    sizes.append(len(cur_index))\n","\n","    # decide the text and val size\n","    text_val_size = max(1, int(len(cur_index) * 0.1)) # at least 1 for both test and val\n","    cur_index_resized = cur_index[:len(cur_index) - 2* text_val_size]\n","    test_index = cur_index[len(cur_index) - 2* text_val_size: len(cur_index) - text_val_size]\n","    val_index = cur_index[len(cur_index) - text_val_size: len(cur_index)]\n","    print(\"sonotype, len of cur:\", typeUsed[i], len(cur_index))\n","    print(\"train, test, val size: \", len(cur_index_resized), len(test_index), len(val_index))\n","\n","    # augment to aug goal\n","    # train\n","    if len(cur_index_resized) > 20:\n","      augment_specs, augment_aux, augment_sono =  augment(specs_h5[cur_index_resized][:20], aux_input_h5[cur_index_resized][:20], np.repeat(i, 20), 1)\n","    else:\n","      augment_num = (int(aug_goal * 0.8) //  len(cur_index_resized)) // 16 + 1   \n","      # train                                                      \n","      augment_specs, augment_aux, augment_sono =  augment(specs_h5[cur_index_resized], aux_input_h5[cur_index_resized], np.repeat(i, len(cur_index_resized)), augment_num)\n","    \n","    aug_index = np.arange(2, len(augment_specs)) # first in augmented set is itself\n","    random.shuffle(aug_index)\n","    aug_index = aug_index[:int(aug_goal * 0.8) -  len(cur_index_resized)] \n","    print(\"test aug size\",len(aug_index))\n","\n","    if len(specs):\n","      specs = np.concatenate( (specs, specs_h5[cur_index_resized], augment_specs[aug_index]) , axis = 0)\n","      aux_input = np.concatenate( (aux_input, aux_input_h5[cur_index_resized], augment_aux[aug_index]), axis= 0)\n","      sonotypes = np.append(sonotypes, np.repeat(i, len(cur_index_resized) + len(aug_index)))\n","    else:\n","      specs = np.concatenate( (specs_h5[cur_index_resized], augment_specs[aug_index]) , axis = 0)\n","      aux_input = np.concatenate( (aux_input_h5[cur_index_resized], augment_aux[aug_index]), axis= 0)\n","      sonotypes = np.repeat(i, len(cur_index_resized) + len(aug_index))\n","\n","    # test and val\n","    augment_num = (int(aug_goal * 0.1) // text_val_size) // 16 + 1   \n","    # test\n","    augment_specs, augment_aux, augment_sono = None, None, None\n","    augment_specs, augment_aux, augment_sono =  augment(specs_h5[test_index], aux_input_h5[test_index], np.repeat(i, len(test_index)), augment_num)\n","    aug_index = np.arange(2, len(augment_specs))\n","    random.shuffle(aug_index)\n","    aug_index = aug_index[:int(aug_goal * 0.1) - text_val_size]  \n","    print(\"test aug size\",len(aug_index))\n","\n","    if len(spec_test):\n","      spec_test = np.concatenate( (spec_test, specs_h5[test_index], augment_specs[aug_index]) , axis = 0)\n","      aux_test = np.concatenate( (aux_test, aux_input_h5[test_index], augment_aux[aug_index]), axis= 0)\n","      y_test = np.append(y_test, np.repeat(i, len(test_index) + len(aug_index)))\n","    else:\n","      spec_test = np.concatenate( (specs_h5[test_index], augment_specs[aug_index]) , axis = 0)\n","      aux_test = np.concatenate( (aux_input_h5[test_index], augment_aux[aug_index]), axis= 0)\n","      y_test = np.repeat(i, len(test_index) + len(aug_index))\n","\n","    # val\n","    augment_specs, augment_aux, augment_sono = None, None, None\n","    augment_specs, augment_aux, augment_sono =  augment(specs_h5[val_index], aux_input_h5[val_index], np.repeat(i, len(val_index)), augment_num)\n","    aug_index = np.arange(2, len(augment_specs))\n","    random.shuffle(aug_index)\n","    aug_index = aug_index[:int(aug_goal * 0.1) - text_val_size]  \n","\n","    if len(spec_val):\n","      spec_val = np.concatenate( (spec_val, specs_h5[val_index], augment_specs[aug_index]) , axis = 0)\n","      aux_val = np.concatenate( (aux_val, aux_input_h5[val_index], augment_aux[aug_index]), axis= 0)\n","      y_val = np.append(y_val, np.repeat(i, len(val_index) + len(aug_index)))\n","    else:\n","      spec_val = np.concatenate( (specs_h5[val_index], augment_specs[aug_index]) , axis = 0)\n","      aux_val = np.concatenate( (aux_input_h5[val_index], augment_aux[aug_index]), axis= 0)\n","      y_val = np.repeat(i, len(val_index) + len(aug_index))\n","\n","\n","    print()\n","    print(specs.shape, len(aux_input), len(sonotypes), len(spec_test), len(aux_test), len(y_test), len(spec_val), len(aux_val), len(y_val) )\n","    print()\n","\n","  x_test = [spec_test, aux_test]\n","  x_val = [spec_val, aux_val]\n","  cat_y_test = to_categorical(pd.factorize(y_test)[0],num_classes= len(typeUsed))\n","  cat_y_val = to_categorical(pd.factorize(y_val)[0],num_classes= len(typeUsed))\n","\n","  print(\"train, test, val size:\", specs.shape[0], len(cat_y_test), len(cat_y_val))\n","\n","  return typeUsed, sizes, specs, aux_input, sonotypes, x_test, x_val, cat_y_test, cat_y_val\n","\n","# a = get_samples(4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2SPfYlxl_rVd"},"source":["class TestCallback(keras.callbacks.Callback):\n","    def __init__(self, test_data):\n","        self.test_data = test_data\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        x, y = self.test_data\n","        loss, acc = self.model.evaluate(x, y, verbose=0)\n","        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n","\n","        # stop training if training \n","        # accuracy = logs[\"val_accuracy\"]\n","        if acc >= 1 or logs[\"val_accuracy\"] >= 1:\n","            self.model.stop_training = True "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxWSth2UxoyE"},"source":["def gen(specs, aux_input, sonotypes):\n","  # augment_specs, augment_aux, augment_sono =  augment(specs_seperated[i], aux_seperated[i], sono_seperated[i], 1)\n","  while 1:\n","    # shuffle data\n","    indices = np.arange(len(sonotypes))\n","    np.random.shuffle(indices)\n","    # # use 30 of all data per epoch\n","    # indices = indices[:30]\n","    step_len = 4\n","\n","    for i in range(len(specs) // step_len):\n","      step_min = i * step_len\n","      step_max = min( (i + 1) * step_len, len(specs) )\n","      \n","      augment_specs, augment_aux, augment_sono =  augment(specs[indices][step_min: step_max], aux_input[indices][step_min: step_max], sonotypes[indices][step_min: step_max], 1)\n","      augment_specs_normal = normalize(augment_specs)\n","      cat_y_train = to_categorical(augment_sono, num_classes= len(typeUsed))\n","      \n","      yield {'input_1': np.array([augment_specs_normal])[0], 'aux_input': np.array([augment_aux])[0]}, np.array([cat_y_train])[0]\n","     \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-Y0Xrs3Atxv"},"source":["config = dict(\n","    dropout = 0.5,\n","    hidden = 1024,\n","    learn_rate = 0.00001,\n","    epochs = 30,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"so-g_G7oAtxw"},"source":["def build_finetune_model(base_model, dropouts, fc_layers, num_classes):\n","    for layer in base_model.layers:\n","       layer.trainable = False\n","\n","    x = base_model.output\n","    x = Flatten()(x)\n","\n","    # add input layer\n","    auxiliary_input = Input(shape=(4,), name='aux_input')\n","    x = concatenate([x, auxiliary_input])\n","\n","    for fc, drop in zip(fc_layers, dropouts):\n","        x = Dense(fc, activation='relu')(x) \n","        x = Dropout(drop)(x)\n","\n","    predictions = Dense(num_classes, activation='softmax')(x)\n","\n","    finetune_model = Model(inputs=[base_model.input,auxiliary_input], outputs=predictions)\n","    # finetune_model = Model(inputs=base_model.input, outputs=predictions)\n","\n","    return finetune_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nc7oojHRURvm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00134805-1743-468c-b712-0ca67a6126b4"},"source":["numUsed =6\n","all_result = []\n","all_result_no = []\n","all_type_used = []\n","\n","for i in range(100):\n","  print(\"\\niteration: \", i)\n","  tf.keras.backend.clear_session()\n","  typeUsed, sizes, specs, aux_input, sonotypes, x_test, x_val, cat_y_test, cat_y_val = None, None, None, None, None, None, None, None,None\n","  \n","  typeUsed, sizes, specs, aux_input, sonotypes, x_test, x_val, cat_y_test, cat_y_val = get_samples(numUsed)\n","  all_type_used.append(typeUsed)\n","  print(\"all type used\", all_type_used)\n","\n","  # train w/o augmentation\n","  model = None\n","  keras.backend.clear_session()\n","  model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n","  model = build_finetune_model(model, \n","                              [config[\"dropout\"], config[\"dropout\"]], \n","                              [config[\"hidden\"], config[\"hidden\"]], \n","                              len(typeUsed))\n","\n","  filepath = 'My Drive/Stethoscope/model_group.hdf5'\n","  earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n","  checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","  opt = Adam(lr=config[\"learn_rate\"])\n","  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","  cat_y_train = to_categorical(sonotypes, num_classes= len(typeUsed))\n","\n","  history = model.fit(x=[specs, aux_input], y=cat_y_train, validation_data=(x_val, cat_y_val), epochs=300, verbose = 2, callbacks = [checkpoint, earlystop, TestCallback((x_test, cat_y_test))])\n","  \n","  # write train log to file\n","  hist_df = pd.DataFrame(history.history) \n","  # save to csv: \n","  hist_csv_file = 'My Drive/Stethoscope/training_history_no.csv'\n","  with open(hist_csv_file, mode='a') as f:\n","      hist_df.to_csv(f)\n","  history = None\n","\n","  # test: load the model with best weights\n","  model = None\n","  keras.backend.clear_session()\n","  model = load_model (filepath)\n","\n","  results = model.evaluate( x= x_test, y=cat_y_test)\n","  all_result_no.append(results)\n","  print(\"test loss, test acc:\", results)\n","  print(all_result_no)\n","\n","  # save result to csv\n","  with open('My Drive/Stethoscope/test_result_no.csv', 'a+') as f:\n","    # for key in all_result_no.keys():\n","    f.write(\"%s, %s, %s\\n\"%( \"; \".join(map(str, typeUsed.flatten())), \"; \".join(map(str, sizes)), \", \".join(map(str,results))) )\n"],"execution_count":null,"outputs":[]}]}