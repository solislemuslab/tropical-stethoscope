{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7xnoDEz8R-Z",
        "outputId": "3fe2dec5-2b49-43f7-e730-b347d0844e5b"
      },
      "outputs": [],
      "source": [
        "# If run this file on google colab:\n",
        "# Please use GPU for colab as CPU runtime would make the trainig process extremely slow\n",
        "# It can be found in Notebook settings or Runtime > Change runtime type\n",
        "# select GPU as Hardware accelerator.\n",
        "# There are a limit for using GPU on google colab for free in a period of time\n",
        "# but the quota is enough just to tryout this notebook\n",
        "\n",
        "import h5py\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Input, concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "# Check the tensorflow version. We use tensorflow 2.6.0 in this example,\n",
        "# but the script should work for all tensorflow 2.x versions.\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NeB0pNE8cAe"
      },
      "outputs": [],
      "source": [
        "# if using google colab, run the following lines\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# give colab the right to access your file\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VSf-dXWsHbV"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vdu4viHsDyH"
      },
      "outputs": [],
      "source": [
        "def normalize(specs):\n",
        "  '''\n",
        "  Linear normalization of the data\n",
        "  @param: specs is the list of spcetrograms to normalize\n",
        "  @return: the normalized spectrograms\n",
        "  '''\n",
        "\n",
        "  return_specs = []\n",
        "  for i in range(len(specs)):\n",
        "    # make a copy to ensure not changing the original spectrogram\n",
        "    cur_spec = np.copy(specs[i])\n",
        "    s_min = np.amin(cur_spec)\n",
        "    s_max = np.amax(cur_spec)\n",
        "    return_specs.append((cur_spec - s_min)/(s_max - s_min) * 255)\n",
        "\n",
        "  return np.array(return_specs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Divm4kJd-ufK"
      },
      "source": [
        "# Augmentation Methods\n",
        "\n",
        "For each function, make a copy of the original spectrogram\n",
        "to ensure that we do not change the original one\n",
        "\n",
        "Return all the augmented spectrograms in lists for consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeHY3yeO-0FX"
      },
      "outputs": [],
      "source": [
        "def time_chop(spec, rand_start):\n",
        "  '''\n",
        "  chop the spectrogram on x axis (time) from the right\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: rand_start: the randomed index to start chopping\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  time_chopped_spec = np.copy(spec)\n",
        "  time_chopped_spec[:,224 - rand_start:,:] = 0\n",
        "\n",
        "  return [time_chopped_spec]\n",
        "\n",
        "def freq_chop(spec, rand_start):\n",
        "  '''\n",
        "  chop the spectrogram on y axis (frequency) from the top\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: rand_start: the randomed index to start chopping\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  freq_chopped_spec = np.copy(spec)\n",
        "  freq_chopped_spec[0:rand_start,:,:] = 0\n",
        "\n",
        "  return [freq_chopped_spec]\n",
        "\n",
        "def four_chop(spec, rand_start):\n",
        "  '''\n",
        "  chop the spectrogram on four sides\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: rand_start: the randomed index to start chopping\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  four_chopped_spec = np.copy(spec)\n",
        "  four_chopped_spec[0 : rand_start,:,:] = 0  # top\n",
        "  four_chopped_spec[:,224 - rand_start:,:] = 0  # right\n",
        "  four_chopped_spec[224 - rand_start:,:,:] = 0  # bottom\n",
        "  four_chopped_spec[:, 0 : rand_start ,:] = 0  # left\n",
        "\n",
        "  return [four_chopped_spec]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s1Hlo6q9-BC"
      },
      "outputs": [],
      "source": [
        "def add_noises(spec):\n",
        "  '''\n",
        "  add noise to the spectrogram with 1/3 ratio\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "  # add noise from light rian -2, rain -3, heavy rain -4, thunder -5, aircraft -6, chainsaw -7, and car/truck -8\n",
        "  return_specs = []\n",
        "  noise_sonos = [-2, -3, -4, -5,-6,-7,-8]\n",
        "\n",
        "  for i in range(len(noise_sonos)):\n",
        "    noises_index = np.argwhere(sonotypes_h5 == noise_sonos[i]).flatten()\n",
        "    noises = specs_h5[noises_index]\n",
        "    # randomly pick a noise sample\n",
        "    index = random.randint(0, len(noises) - 1)\n",
        "    # normalize sound and noise, add them together with 1/3 ratio\n",
        "    noise = normalize(np.array(noises[index]) / 3)\n",
        "    return_specs.append(np.add(normalize([np.copy(spec)])[0], noise))\n",
        "\n",
        "  return return_specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3lLYDZU_VAJ"
      },
      "outputs": [],
      "source": [
        "def translate(spec, roll_start):\n",
        "  '''\n",
        "  roll the spectrogram up and down\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: roll_start, the index to start rolling\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  return_specs = []\n",
        "  return_specs.append(np.roll(spec, -roll_start, axis = 0))\n",
        "  return_specs.append(np.roll(spec, roll_start, axis = 0))\n",
        "\n",
        "  return return_specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMRDhokq_Wg9"
      },
      "outputs": [],
      "source": [
        "def widen(spec, widen_index):\n",
        "  '''\n",
        "  widen the spectrogram\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: widen_index, the index to decide the start and end of\n",
        "          the spectrogram to widen\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "  return_specs = []\n",
        "  widen_time_spec=cv2.resize(spec.astype('float32'),(224 + widen_index,224))\n",
        "  widen_freq_spec=cv2.resize(spec.astype('float32'),(224,224 + widen_index))\n",
        "\n",
        "  return_specs.append(widen_time_spec[:,widen_index // 2: -widen_index // 2,:])\n",
        "  return_specs.append(widen_freq_spec[widen_index // 2: -widen_index // 2,:,:])\n",
        "\n",
        "  return return_specs\n",
        "\n",
        "def squeeze(spec, squeeze_index):\n",
        "  '''\n",
        "  squeeze the spectrogram\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: widen_index, the index to decide the start and end of\n",
        "          the spectrogram to widen\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  squeezed=cv2.resize(spec.astype('float32'),(224 - squeeze_index,224 - squeeze_index))\n",
        "  squeeze_spec = np.zeros([224, 224, 3])\n",
        "  squeeze_spec[squeeze_index//2 : - squeeze_index //2,squeeze_index//2 : - squeeze_index //2, :] = squeezed\n",
        "\n",
        "  return [squeeze_spec]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfJQnb19kqGn"
      },
      "outputs": [],
      "source": [
        "def augment(specs, aux_input, sonotypes, aug_num, augment_range = 0.1):\n",
        "  '''\n",
        "  call all the augment methods on the spectrograms\n",
        "\n",
        "  @param: specs is the list of spectrograms to augment from\n",
        "  @param: aux_input is the list of auxiliary input corresponds to the spectrograms\n",
        "  @param: sonotypes is the list of sonnotypes corresponds to the spectrograms\n",
        "  @param: aug_num is the number of sets of augmented spectrograms\n",
        "          (returned number of samples will be 1 + 15*aug_num)\n",
        "  @param: augment_range is the threshold used for augmentations, default to 0.1\n",
        "  @return: augment_specs_func is the list of augmented spectrograms\n",
        "  @return: augment_aux_func is the list of  auxiliary input corresponds to the spectrograms\n",
        "  @return: augment_sono_func is the list of sonotypes input corresponds to the spectrograms\n",
        "  '''\n",
        "\n",
        "  augment_specs_func = []\n",
        "  augment_aux_func = []\n",
        "  augment_sono_func = []\n",
        "\n",
        "  # print(len(aux_input))\n",
        "  for i in range(len(specs)):\n",
        "    # generate random index array for augmentation\n",
        "    # in 5% to 10% of the size of the original spectrogram\n",
        "    # 224 * 224 is the image size\n",
        "    indices = np.arange(int(224 * augment_range / 3 * 2) , int(224 * augment_range))\n",
        "    np.random.shuffle(indices)\n",
        "    indices = indices[:aug_num]\n",
        "\n",
        "    # augment each spec and add to list\n",
        "    cur_spec = np.copy(specs[i])\n",
        "    # add itself to the list\n",
        "    if (len(augment_specs_func)):\n",
        "      augment_specs_func = np.append(augment_specs_func, [cur_spec], axis = 0)\n",
        "    else:\n",
        "      augment_specs_func.append(cur_spec)\n",
        "    # augment_specs_func.append(cur_spec)\n",
        "\n",
        "    for index in indices:\n",
        "      # print(index)\n",
        "      # chop\n",
        "      augment_specs_func = np.append(augment_specs_func, time_chop( np.copy(cur_spec), index), axis = 0)\n",
        "      augment_specs_func = np.append(augment_specs_func, freq_chop( np.copy(cur_spec), index), axis = 0)\n",
        "      augment_specs_func = np.append(augment_specs_func, four_chop( np.copy(cur_spec), index), axis = 0)\n",
        "\n",
        "      # widen + squeeze\n",
        "      augment_specs_func = np.append(augment_specs_func, squeeze( np.copy(cur_spec), index), axis = 0)\n",
        "      augment_specs_func = np.append(augment_specs_func, widen( np.copy(cur_spec), index), axis = 0)\n",
        "\n",
        "      # noise\n",
        "      augment_specs_func = np.append(augment_specs_func, add_noises(np.copy(cur_spec)), axis = 0)\n",
        "\n",
        "      # translate\n",
        "      augment_specs_func = np.append(augment_specs_func, translate(np.copy(cur_spec), index), axis = 0)\n",
        "\n",
        "    # total 1 + 15 * aug_num augmented, repeat the sono and aux\n",
        "    if (len(augment_aux_func)):\n",
        "      augment_aux_func = np.append(augment_aux_func, np.repeat([aux_input[i]], 1 + 15 * aug_num, axis = 0), axis= 0)\n",
        "    else:\n",
        "      augment_aux_func = np.repeat([aux_input[i]], 1 + 15 * aug_num, axis = 0)\n",
        "\n",
        "    augment_sono_func = np.append(augment_sono_func, np.repeat(sonotypes[i], 1 + 15 * aug_num), axis= 0)\n",
        "\n",
        "  return augment_specs_func, augment_aux_func, augment_sono_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLv434W3FpAr"
      },
      "outputs": [],
      "source": [
        "def augment_random_one(specs, aux_input, sonotypes, augment_range = 0.1, repeat_num = 1):\n",
        "  '''\n",
        "  Randomly call one of the augment methods on the spectrograms and generate\n",
        "  repeat_num extra sample for each sample\n",
        "\n",
        "  @param: specs is the list of spectrograms to augment from\n",
        "  @param: aux_input is the list of auxiliary input corresponds to the spectrograms\n",
        "  @param: sonotypes is the list of sonnotypes corresponds to the spectrograms\n",
        "  @param: augment_range is the threshold used for augmentations, default to 0.1\n",
        "  @param: repeat_num times to repeat random augmentation process\n",
        "  @return: augment_specs_func is the list of augmented spectrograms\n",
        "  @return: augment_aux_func is the list of  auxiliary input corresponds to the spectrograms\n",
        "  @return: augment_sono_func is the list of sonotypes input corresponds to the spectrograms\n",
        "  '''\n",
        "  augment_specs_func = []\n",
        "  augment_aux_func = []\n",
        "  augment_sono_func = []\n",
        "\n",
        "  augment_functions = [time_chop, freq_chop, four_chop, squeeze, widen, add_noises, translate]\n",
        "  indices = np.arange(int(224 * augment_range / 3 * 2) , int(224 * augment_range))\n",
        "\n",
        "  for i in range(len(specs)):\n",
        "    for _ in range(repeat_num):\n",
        "      cur_spec = np.copy(specs[i])\n",
        "      selected_function = random.choice(augment_functions)\n",
        "      if selected_function.__name__ == \"add_noises\":\n",
        "        cur_augment_specs = selected_function(cur_spec)\n",
        "      else:\n",
        "        # Generate index for augmentation\n",
        "        index = random.choice(indices)\n",
        "        cur_augment_specs = selected_function(cur_spec, index)\n",
        "\n",
        "      cur_augment_spec = random.choice(cur_augment_specs)\n",
        "      if (len(augment_specs_func)):\n",
        "        augment_specs_func = np.append(augment_specs_func, [cur_augment_spec], axis = 0)\n",
        "      else:\n",
        "        augment_specs_func.append(cur_augment_spec)\n",
        "\n",
        "    if (len(augment_aux_func)):\n",
        "      augment_aux_func = np.append(augment_aux_func, np.repeat([aux_input[i]], repeat_num, axis = 0), axis= 0)\n",
        "    else:\n",
        "      augment_aux_func = np.repeat([aux_input[i]], repeat_num, axis = 0)\n",
        "\n",
        "    augment_sono_func = np.append(augment_sono_func,  np.repeat(sonotypes[i], repeat_num), axis= 0)\n",
        "\n",
        "  return augment_specs_func, augment_aux_func, augment_sono_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbACb2wJFvFE"
      },
      "source": [
        "# Read dataset and randomly select samples with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFIesA2xFxN7"
      },
      "outputs": [],
      "source": [
        "f =  h5py.File('Shareddrives/personal/samples.hdf5', \"r\")\n",
        "\n",
        "specs_h5 = np.array(f[\"specs\"]).astype(\"float32\")\n",
        "sonotypes_h5 = np.array(f[\"sonotypes\"]).astype(\"float32\")\n",
        "times_h5 = np.array(f[\"times\"]).astype(\"float32\")\n",
        "freqs_h5 = np.array(f[\"freqs\"]).astype(\"float32\")\n",
        "groups_h5 = np.array(f[\"groups\"])\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efoXfYCZF3v5"
      },
      "outputs": [],
      "source": [
        "# append x_times an x_freqs to be auxiliary_input\n",
        "aux_input_h5 = np.append(times_h5, freqs_h5, axis=1)\n",
        "\n",
        "# create the dictionary for sonotypes and groups\n",
        "sono2group = dict(zip(sonotypes_h5, groups_h5))\n",
        "\n",
        "# get the data for top k sonotypes\n",
        "s_unique, s_freq = np.unique(sonotypes_h5, return_counts=True)\n",
        "s_freq_order = np.argsort(s_freq)[::-1]\n",
        "s_freq_desc = s_freq[s_freq_order]\n",
        "\n",
        "numUsed = 6\n",
        "num_pick = 49"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSL_MeuGF17F"
      },
      "outputs": [],
      "source": [
        "def get_samples(numUsed, min_type, aug_goal = 250, fixed_size = False):\n",
        "    # get groups\n",
        "    type_index = np.argwhere((s_freq_desc >= min_type) & (\n",
        "        s_unique[s_freq_order] > 0)).flatten()\n",
        "    random.shuffle(type_index)\n",
        "    type_index = np.sort(type_index[:numUsed])\n",
        "    max_num = s_freq_desc[np.min(type_index)]\n",
        "    typeUsed = s_unique[s_freq_order][type_index]\n",
        "\n",
        "    print(\"type index:\", type_index)\n",
        "    print(\"type used: \", typeUsed)\n",
        "    print(\"max num: \", max_num)\n",
        "\n",
        "    # aug\n",
        "    specs = []\n",
        "    aux_input = []\n",
        "    sonotypes = []\n",
        "    spec_test = []\n",
        "    aux_test = []\n",
        "    y_test = []\n",
        "    spec_val = []\n",
        "    aux_val = []\n",
        "    y_val = []\n",
        "    sizes = []\n",
        "\n",
        "    # no aug\n",
        "    specs_no = []\n",
        "    aux_input_no = []\n",
        "    sonotypes_no = []\n",
        "    spec_test_no = []\n",
        "    aux_test_no = []\n",
        "    y_test_no = []\n",
        "    spec_val_no = []\n",
        "    aux_val_no = []\n",
        "    y_val_no = []\n",
        "\n",
        "    for i in range(len(typeUsed)):\n",
        "        # get index of the current type of spec\n",
        "        cur_index = np.argwhere(sonotypes_h5 == typeUsed[i]).flatten()\n",
        "        random.shuffle(cur_index)\n",
        "        # fixed size, comment off next line if use the original size\n",
        "        if fixed_size:\n",
        "          cur_index = cur_index[:min_type]\n",
        "        sizes.append(len(cur_index))  # append the used size\n",
        "\n",
        "        # decide the text and val size, at least 1 for both test and val\n",
        "        text_val_size = max(1, int(len(cur_index) * 0.1))\n",
        "        cur_index_resized = cur_index[:len(cur_index) - 2 * text_val_size]\n",
        "        test_index = cur_index[len(cur_index) - 2 *\n",
        "                               text_val_size: len(cur_index) - text_val_size]\n",
        "        val_index = cur_index[len(cur_index) - text_val_size: len(cur_index)]\n",
        "        print(\"\\nsonotype, len of cur:\", typeUsed[i], len(cur_index))\n",
        "        print(\"train, test, val size: \", len(cur_index_resized),\n",
        "              len(test_index), len(val_index))\n",
        "\n",
        "        # augment to aug goal\n",
        "        # train\n",
        "        if int(aug_goal * 0.8) > len(cur_index_resized):\n",
        "          augment_repeat_cnt = int(aug_goal * 0.8) // len(cur_index_resized)\n",
        "          augment_specs, augment_aux, augment_sono = augment_random_one(\n",
        "                        specs_h5[cur_index_resized],\n",
        "                        aux_input_h5[cur_index_resized],\n",
        "                        np.repeat(i, len(cur_index_resized)),\n",
        "                        repeat_num = augment_repeat_cnt\n",
        "                        )\n",
        "        else:\n",
        "          augment_specs, augment_aux, augment_sono =  specs_h5[cur_index_resized], aux_input_h5[cur_index_resized], np.repeat(i, len(cur_index_resized)),\n",
        "\n",
        "        aug_index = np.arange(len(augment_specs))\n",
        "        random.shuffle(aug_index)\n",
        "        aug_index = aug_index[:int(aug_goal * 0.8) - len(cur_index_resized)]\n",
        "        print(\"test aug size\", len(aug_index))\n",
        "\n",
        "        if len(specs):\n",
        "            specs = np.concatenate(\n",
        "                (specs, specs_h5[cur_index_resized], augment_specs[aug_index]), axis=0)\n",
        "            aux_input = np.concatenate(\n",
        "                (aux_input, aux_input_h5[cur_index_resized], augment_aux[aug_index]), axis=0)\n",
        "            sonotypes = np.append(sonotypes, np.repeat(\n",
        "                i, len(cur_index_resized) + len(aug_index)))\n",
        "\n",
        "            specs_no = np.concatenate(\n",
        "                (specs_no, specs_h5[cur_index_resized]), axis=0)\n",
        "            aux_input_no = np.concatenate(\n",
        "                (aux_input_no, aux_input_h5[cur_index_resized]), axis=0)\n",
        "            sonotypes_no = np.append(sonotypes_no, np.repeat(\n",
        "                i, len(cur_index_resized)))\n",
        "        else:\n",
        "            specs = np.concatenate(\n",
        "                (specs_h5[cur_index_resized], augment_specs[aug_index]), axis=0)\n",
        "            aux_input = np.concatenate(\n",
        "                (aux_input_h5[cur_index_resized], augment_aux[aug_index]), axis=0)\n",
        "            sonotypes = np.repeat(i, len(cur_index_resized) + len(aug_index))\n",
        "\n",
        "            specs_no = np.copy(specs_h5[cur_index_resized])\n",
        "            aux_input_no = np.copy(aux_input_h5[cur_index_resized])\n",
        "            sonotypes_no = np.repeat(i, len(cur_index_resized))\n",
        "\n",
        "        # test and val\n",
        "        # augment_num = (int(aug_goal * 0.1) // text_val_size) // 16 + 1\n",
        "        augment_repeat_cnt = int(aug_goal * 0.1) // len(test_index)\n",
        "        augment_specs, augment_aux, augment_sono = None, None, None\n",
        "        # test\n",
        "        if int(aug_goal * 0.1) > len(test_index):\n",
        "          augment_repeat_cnt = int(aug_goal * 0.1) // len(test_index)\n",
        "          augment_specs, augment_aux, augment_sono = augment_random_one(\n",
        "                        specs_h5[test_index],\n",
        "                        aux_input_h5[test_index],\n",
        "                        np.repeat(i, len(test_index)),\n",
        "                        repeat_num = augment_repeat_cnt\n",
        "                        )\n",
        "        else:\n",
        "          augment_specs, augment_aux, augment_sono =  specs_h5[test_index], aux_input_h5[test_index], np.repeat(i, len(test_index))\n",
        "\n",
        "        aug_index = np.arange(len(augment_specs))\n",
        "        random.shuffle(aug_index)\n",
        "        aug_index = aug_index[:int(aug_goal * 0.1) - text_val_size]\n",
        "        print(\"test aug size\", len(aug_index))\n",
        "\n",
        "        if len(spec_test):\n",
        "            spec_test = np.concatenate(\n",
        "                (spec_test, specs_h5[test_index], augment_specs[aug_index]), axis=0)\n",
        "            aux_test = np.concatenate(\n",
        "                (aux_test, aux_input_h5[test_index], augment_aux[aug_index]), axis=0)\n",
        "            y_test = np.append(y_test, np.repeat(\n",
        "                i, len(test_index) + len(aug_index)))\n",
        "\n",
        "            spec_test_no = np.concatenate(\n",
        "                (spec_test_no, specs_h5[test_index]), axis=0)\n",
        "            aux_test_no = np.concatenate(\n",
        "                (aux_test_no, aux_input_h5[test_index]), axis=0)\n",
        "            y_test_no = np.append(y_test_no, np.repeat(i, len(test_index)))\n",
        "\n",
        "        else:\n",
        "            spec_test = np.concatenate(\n",
        "                (specs_h5[test_index], augment_specs[aug_index]), axis=0)\n",
        "            aux_test = np.concatenate(\n",
        "                (aux_input_h5[test_index], augment_aux[aug_index]), axis=0)\n",
        "            y_test = np.repeat(i, len(test_index) + len(aug_index))\n",
        "\n",
        "            spec_test_no = np.copy(specs_h5[test_index])\n",
        "            aux_test_no = np.copy(aux_input_h5[test_index])\n",
        "            y_test_no = np.repeat(i, len(test_index))\n",
        "\n",
        "        # val\n",
        "        augment_repeat_cnt = int(aug_goal * 0.1) // len(val_index)\n",
        "        augment_specs, augment_aux, augment_sono = None, None, None\n",
        "        # test\n",
        "        if int(aug_goal * 0.1) > len(val_index):\n",
        "          augment_repeat_cnt = int(aug_goal * 0.1) // len(val_index)\n",
        "          augment_specs, augment_aux, augment_sono = augment_random_one(\n",
        "                        specs_h5[val_index],\n",
        "                        aux_input_h5[val_index],\n",
        "                        np.repeat(i, len(val_index)),\n",
        "                        repeat_num = augment_repeat_cnt\n",
        "                        )\n",
        "        else:\n",
        "          augment_specs, augment_aux, augment_sono =  specs_h5[val_index], aux_input_h5[val_index], np.repeat(i, len(val_index))\n",
        "\n",
        "        aug_index = np.arange(len(augment_specs))\n",
        "        random.shuffle(aug_index)\n",
        "        aug_index = aug_index[:int(aug_goal * 0.1) - text_val_size]\n",
        "\n",
        "        if len(spec_val):\n",
        "            spec_val = np.concatenate(\n",
        "                (spec_val, specs_h5[val_index], augment_specs[aug_index]), axis=0)\n",
        "            aux_val = np.concatenate(\n",
        "                (aux_val, aux_input_h5[val_index], augment_aux[aug_index]), axis=0)\n",
        "            y_val = np.append(y_val, np.repeat(\n",
        "                i, len(val_index) + len(aug_index)))\n",
        "\n",
        "            spec_val_no = np.concatenate(\n",
        "                (spec_val_no, specs_h5[val_index]), axis=0)\n",
        "            aux_val_no = np.concatenate(\n",
        "                (aux_val_no, aux_input_h5[val_index]), axis=0)\n",
        "            y_val_no = np.append(y_val_no, np.repeat(i, len(val_index)))\n",
        "        else:\n",
        "            spec_val = np.concatenate(\n",
        "                (specs_h5[val_index], augment_specs[aug_index]), axis=0)\n",
        "            aux_val = np.concatenate(\n",
        "                (aux_input_h5[val_index], augment_aux[aug_index]), axis=0)\n",
        "            y_val = np.repeat(i, len(val_index) + len(aug_index))\n",
        "\n",
        "            spec_val_no = np.copy(specs_h5[val_index])\n",
        "            aux_val_no = np.copy(aux_input_h5[val_index])\n",
        "            y_val_no = np.repeat(i, len(val_index))\n",
        "\n",
        "\n",
        "        print(\"Cur sizes for validation\", end=\":\")\n",
        "        print(specs.shape, len(aux_input), len(sonotypes), len(spec_test), len(\n",
        "            aux_test), len(y_test), len(spec_val), len(aux_val), len(y_val))\n",
        "\n",
        "    # aug\n",
        "    specs = normalize(specs)\n",
        "    x_test = [normalize(spec_test), aux_test]\n",
        "    x_val = [normalize(spec_val), aux_val]\n",
        "    cat_y_test = to_categorical(pd.factorize(\n",
        "        y_test)[0], num_classes=len(typeUsed))\n",
        "    cat_y_val = to_categorical(pd.factorize(\n",
        "        y_val)[0], num_classes=len(typeUsed))\n",
        "\n",
        "    # no aug\n",
        "    specs_no = normalize(specs_no)\n",
        "    x_test_no = [normalize(spec_test_no), aux_test_no]\n",
        "    x_val_no = [normalize(spec_val_no), aux_val_no]\n",
        "    cat_y_test_no = to_categorical(pd.factorize(\n",
        "        y_test_no)[0], num_classes=len(typeUsed))\n",
        "    cat_y_val_no = to_categorical(pd.factorize(\n",
        "        y_val_no)[0], num_classes=len(typeUsed))\n",
        "\n",
        "    print(\"train, test, val size:\", specs.shape[0], len(\n",
        "        cat_y_test), len(cat_y_val))\n",
        "\n",
        "    return typeUsed, sizes, specs, aux_input, sonotypes, x_test, x_val, cat_y_test, cat_y_val,specs_no,aux_input_no, sonotypes_no, x_test_no, x_val_no, cat_y_test_no, cat_y_val_no, y_test_no, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U62DQaQVF8UY"
      },
      "outputs": [],
      "source": [
        "typeUsed, sizes, specs, aux_input, sonotypes, x_test, x_val, cat_y_test, cat_y_val,specs_no,aux_input_no, sonotypes_no, x_test_no, x_val_no, cat_y_test_no, cat_y_val_no, y_test_no, y_test = get_samples(\n",
        "    numUsed, num_pick)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHlMGXpZBET4"
      },
      "source": [
        "# Model and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmpT97hABD3x"
      },
      "outputs": [],
      "source": [
        "# Feel free to play with different configs.\n",
        "config = dict(\n",
        "    dropout = 0.5,\n",
        "    hidden = 1024,\n",
        "    learn_rate = 0.00001,\n",
        "    epochs = 300,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89CFyhKcBHgW"
      },
      "outputs": [],
      "source": [
        "def build_finetune_model(base_model, dropouts, fc_layers, num_classes):\n",
        "    '''\n",
        "    finetune the model, freeze teh top layers,\n",
        "    add dropouts, dense layers,\n",
        "    another input layer for auxiliary input\n",
        "    and concatenate it with the flatten layer\n",
        "    '''\n",
        "\n",
        "    # freeze the base layers\n",
        "    for layer in base_model.layers:\n",
        "       layer.trainable = False\n",
        "\n",
        "    # add flatten layer\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # add input layer for auxiliary input (time and frequency)\n",
        "    auxiliary_input = Input(shape=(4,), name='aux_input')\n",
        "    x = concatenate([x, auxiliary_input])\n",
        "\n",
        "    #  dense and dropout layer\n",
        "    for fc, drop in zip(fc_layers, dropouts):\n",
        "        x = Dense(fc, activation='relu')(x)\n",
        "        x = Dropout(drop)(x)\n",
        "\n",
        "    # final dense layer for output\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    finetune_model = Model(inputs=[base_model.input,auxiliary_input], outputs=predictions)\n",
        "\n",
        "    return finetune_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6id17t85n_3p"
      },
      "outputs": [],
      "source": [
        "class TestCallback(keras.callbacks.Callback):\n",
        "    '''\n",
        "    The class used to see the test result during training\n",
        "    '''\n",
        "\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        x, y = self.test_data\n",
        "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
        "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r8uQ7upBJBe",
        "outputId": "aa8cb03e-69d1-41e0-91ed-a6c4bdf0e41c"
      },
      "outputs": [],
      "source": [
        "model = None\n",
        "keras.backend.clear_session()\n",
        "# get the pretrained model\n",
        "model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "# finetune to our case\n",
        "model = build_finetune_model(model,\n",
        "                             [config[\"dropout\"], config[\"dropout\"]],\n",
        "                             [config[\"hidden\"], config[\"hidden\"]],\n",
        "                             len(typeUsed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvacKNbVBOTe"
      },
      "outputs": [],
      "source": [
        "# # model stats, remove \"#\" in lines below to print\n",
        "# model.summary()\n",
        "# plot_model(model,to_file = 'file-to-store-png.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1vd2PGgjfHl",
        "outputId": "2275fecb-175b-4397-8d0e-3de028d38d2b"
      },
      "outputs": [],
      "source": [
        "# earlystopping, checkpoiint, before\n",
        "filepath_loss = 'Shareddrives/personal/model_loss.hdf5'\n",
        "\n",
        "earlystop = EarlyStopping(\n",
        "    monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath_loss, monitor='val_loss', verbose=1,\n",
        "                              save_best_only=True, save_weights_only=False, mode='auto', save_freq=\"epoch\")\n",
        "opt = Adam(learning_rate=config[\"learn_rate\"])\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "cat_y_train = to_categorical(sonotypes, num_classes=len(typeUsed))\n",
        "\n",
        "# training\n",
        "history = model.fit(x=[specs, aux_input], y=cat_y_train, validation_data=(\n",
        "    x_val, cat_y_val), epochs=config[\"epochs\"], verbose=2, callbacks=[checkpoint, earlystop, TestCallback((x_test, cat_y_test))])\n",
        "\n",
        "# If we do not want to earlystop, use the next line for training. The model might\n",
        "# be overfitting but the saved model (to filepath_loss) was controlled by using\n",
        "# the model with the lowest validation loss, which does not overfit to the\n",
        "# training samples.\n",
        "history = model.fit(x=[specs, aux_input], y=cat_y_train, validation_data=(\n",
        "    x_val, cat_y_val), epochs=config[\"epochs\"], verbose=2, callbacks=[checkpoint, TestCallback((x_test, cat_y_test))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjVG-8ofGSfr"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p113jhUijjfI",
        "outputId": "9fefa55f-784d-43d1-cc88-ccf562db4e10"
      },
      "outputs": [],
      "source": [
        "# # Evaluate the model\n",
        "# # current model\n",
        "# results = model.evaluate( x= x_test, y=cat_y_test)\n",
        "# print(\"cur test loss, test acc:\", results)\n",
        "\n",
        "# The model with best loss\n",
        "# load the model\n",
        "model = None\n",
        "keras.backend.clear_session()\n",
        "model = load_model (filepath_loss)\n",
        "\n",
        "# evaluate\n",
        "results = model.evaluate( x= x_test, y=cat_y_test)\n",
        "\n",
        "print(\"best loss test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3oCdHJ_BWJ1",
        "outputId": "b245e054-737a-4f4b-f77e-3623e22c4c1a"
      },
      "outputs": [],
      "source": [
        "# ROC/AUC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_score = model.predict(x_test)\n",
        "y_class = [typeUsed[i]\n",
        "            for i in np.argmax(y_score, axis=1)]  # predicted class\n",
        "y_true = [typeUsed[i] for i in y_test]  # true class\n",
        "roc_score = roc_auc_score(\n",
        "    y_test, y_score, sample_weight=None, multi_class=\"ovo\")\n",
        "\n",
        "print(roc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxLNTD3UBWJ2",
        "outputId": "8b9099fd-1ab8-4935-df06-cefbd691f4e6"
      },
      "outputs": [],
      "source": [
        "# precision, recall, f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_predict_index = np.argmax(y_score, axis=1)\n",
        "\n",
        "precision = precision_score(y_test, y_predict_index, average=\"macro\")\n",
        "recall = recall_score(y_test, y_predict_index, average=\"macro\")\n",
        "f1 = f1_score(y_test, y_predict_index, average=\"macro\")\n",
        "\n",
        "print(\"precision:\", precision)\n",
        "print(\"recall:\", recall)\n",
        "print(\"f1 score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gys3EiymHxjI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit (conda)",
      "name": "python373jvsc74a57bd07588a3fb0c9403ab7ab30786f70afa789223f5fe30680232a90046c307ab79c7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
