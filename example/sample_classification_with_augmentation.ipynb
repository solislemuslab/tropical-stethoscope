{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "sample_classification_with_augmentation-tf2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python373jvsc74a57bd07588a3fb0c9403ab7ab30786f70afa789223f5fe30680232a90046c307ab79c7",
      "display_name": "Python 3.7.3 64-bit (conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# If run this file on google colab:\n",
        "# Please use GPU for colab as CPU runtime would make the trainig process extremely slow\n",
        "# It can be found in Notebook settings or Runtime > Change runtime type\n",
        "# select GPU as Hardware accelerator.\n",
        "# There are a limit for using GPU on google colab for free in a period of time\n",
        "# but the quota is enough just to tryout this notebook\n",
        "\n",
        "import h5py\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Input, concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n",
        "# Check the tensorflow version. We use tensorflow 2.6.0 in this example,\n",
        "# but the script should work for all tensorflow 2.x versions.\n",
        "print(tf.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ],
      "metadata": {
        "id": "E7xnoDEz8R-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf84905a-0015-41b6-ac65-4d8883af04be"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# if using google colab, run the following lines\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# give colab the right to access your file\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "id": "3NeB0pNE8cAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425cabc7-5543-44cb-84c6-e9d581b74e53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the dataset"
      ],
      "metadata": {
        "id": "ghR6BTk93CI1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# the data are stored in hdf5 format\n",
        "# formated in five array for specs, sonotypes,\n",
        "# start and end time times, min and max frequencies, and groups\n",
        "\n",
        "f =  h5py.File('My Drive/CNN-example/samples.hdf5', \"r\")\n",
        "\n",
        "specs_h5 = np.array(f[\"specs\"]).astype(\"float32\") # each element is a array of 224 * 224 * 3 floats\n",
        "sonotypes_h5 = np.array(f[\"sonotypes\"]).astype(\"float32\") # each element is an floats\n",
        "times_h5 = np.array(f[\"times\"]).astype(\"float32\") # each element is array of two floats\n",
        "freqs_h5 = np.array(f[\"freqs\"]).astype(\"float32\") # each element is array of two floats\n",
        "groups_h5 = np.array(f[\"groups\"]) # each element is a string\n",
        "\n",
        "f.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "-LTQXpE4zOfG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# append x_times an x_freqs to be auxiliary_input\n",
        "aux_input_h5 = np.append(times_h5,freqs_h5, axis = 1)\n",
        "\n",
        "# print the length and one of the sample\n",
        "print(\"Number of samples:\",aux_input_h5.shape[0])\n",
        "print(\"The auxiliary input of one sample:\",aux_input_h5[10])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 808\n",
            "The auxiliary input of one sample: [21411.273 21412.98  21411.273 21412.98 ]\n"
          ]
        }
      ],
      "metadata": {
        "id": "T-1m0t2Y8m2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce0d0fe-4fc3-4ea9-cd09-ce3377335399"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# create the dictionary for sonotypes and groups\n",
        "sono2group = dict(zip(sonotypes_h5,groups_h5))\n",
        "\n",
        "# sonotype and frequency in decending order\n",
        "s_unique, s_freq = np.unique(sonotypes_h5,return_counts=True)\n",
        "s_freq_order = np.argsort(s_freq)[::-1]\n",
        "s_freq_desc = s_freq[s_freq_order]\n",
        "\n",
        "# print some stat\n",
        "print(\"Number of sonotypes:\", len(s_unique))\n",
        "print(\"Sonotype in decending order of sample size:\", s_unique[s_freq_order][:20])\n",
        "print(\"Sample size:\",s_freq_desc[:20])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sonotypes: 13\n",
            "Sonotype in decending order of sample size: [ 52. 138. 283. 463.  86. 175.  -3.  -4.  -7.  -6.  -2.  -8.  -5.]\n",
            "Sample size: [231 153 109  91  62  49  35  28  24  13   6   4   3]\n"
          ]
        }
      ],
      "metadata": {
        "id": "LrILaIAW8nZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6d6c2e-3c45-4bea-eb25-6c4742f4691b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# pick sonotypes\n",
        "\n",
        "numUsed =6 # number of sonotype to use, at most 6 (will pick 6 if > 6)\n",
        "groupUsed = b'b' # the group to use, the sample dataset only contain birds\n",
        "\n",
        "# randomly pick numUsed number of sonotype\n",
        "# positive sonotype are for bird sounds,\n",
        "# negative sonotypes are for noises used in data agumentation\n",
        "typeUsed = [x for x in s_unique if x > 0]\n",
        "random.shuffle(typeUsed)\n",
        "typeUsed = typeUsed[:numUsed]\n",
        "\n",
        "print(\"Sonotype used:\", typeUsed)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sonotype used: [52.0, 86.0, 175.0, 138.0, 283.0, 463.0]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a9UV4WZ1ILT",
        "outputId": "76557188-e5bf-4c7a-85cc-832973fd3d78"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# get the samples, balanced samples\n",
        "\n",
        "# sample size to use for each sonotype\n",
        "num_pick = 49\n",
        "\n",
        "# train\n",
        "specs = []\n",
        "aux_input = []\n",
        "sonotypes = []\n",
        "\n",
        "# test and validation\n",
        "spec_test = []\n",
        "aux_test = []\n",
        "y_test = []\n",
        "spec_val = []\n",
        "aux_val = []\n",
        "y_val = []\n",
        "\n",
        "for i in range(len(typeUsed)):\n",
        "  # get index of the current type of spec\n",
        "  cur_index = np.argwhere(sonotypes_h5 == typeUsed[i]).flatten()\n",
        "\n",
        "  # categorize into train, validate, and test in 8:1:1 ratio\n",
        "  random.shuffle(cur_index)\n",
        "  cur_index_resized = cur_index[:int(num_pick * 0.8)]\n",
        "  test_index = cur_index[int(num_pick * 0.8): int(num_pick * 0.9)]\n",
        "  val_index = cur_index[int(num_pick * 0.9): num_pick]\n",
        "\n",
        "  # put into each list\n",
        "  if len(specs):\n",
        "    # not null\n",
        "    specs = np.append(specs, specs_h5[cur_index_resized], axis=0)\n",
        "    aux_input = np.append(\n",
        "        aux_input, aux_input_h5[cur_index_resized], axis=0)\n",
        "    # sonotypes in training are start from 0\n",
        "    sonotypes = np.append(sonotypes, np.repeat(i, int(num_pick * 0.8)))\n",
        "    spec_test = np.append(spec_test, specs_h5[test_index], axis=0)\n",
        "    aux_test = np.append(aux_test, aux_input_h5[test_index], axis=0)\n",
        "    spec_val = np.append(spec_val, specs_h5[val_index], axis=0)\n",
        "    aux_val = np.append(aux_val, aux_input_h5[val_index], axis=0)\n",
        "    y_test = np.append(y_test, np.repeat(i, len(test_index)))\n",
        "    y_val = np.append(y_val, np.repeat(i, len(val_index)))\n",
        "  else:\n",
        "    specs = specs_h5[cur_index_resized]\n",
        "    aux_input = aux_input_h5[cur_index_resized]\n",
        "    # sonotypes in training are start from 0\n",
        "    sonotypes = np.repeat(i, int(num_pick * 0.8))\n",
        "    spec_test = specs_h5[test_index]\n",
        "    aux_test = aux_input_h5[test_index]\n",
        "    spec_val = specs_h5[val_index]\n",
        "    aux_val = aux_input_h5[val_index]\n",
        "    y_test = np.repeat(i, len(test_index))\n",
        "    y_val = np.repeat(i, len(val_index))\n",
        "\n",
        "# format the input for test and validation into the required format\n",
        "x_test = [spec_test, aux_test]\n",
        "x_val = [spec_val, aux_val]\n",
        "\n",
        "# categorical the output for test and validation into the required format\n",
        "cat_y_test = to_categorical(pd.factorize(y_test)[0], num_classes=len(typeUsed))\n",
        "cat_y_val = to_categorical(pd.factorize(y_val)[0], num_classes=len(typeUsed))\n",
        "\n",
        "# just make a copy of specs for training\n",
        "specs_keep = np.copy(specs)\n",
        "\n",
        "# just print some stats\n",
        "print(\"Number of sample for tests or validation:\", len(y_test))\n",
        "print(\"Number of samples for training:\", specs.shape[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sample for tests or validation: 30\n",
            "Number of samples for training: 234\n"
          ]
        }
      ],
      "metadata": {
        "id": "zmet4PKD8ow8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1046a9a5-c39e-4167-b873-224b4dd3a00e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization"
      ],
      "metadata": {
        "id": "_VSf-dXWsHbV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "def normalize(specs):\n",
        "  '''\n",
        "  Linear normalization of the data\n",
        "  @param: specs is the list of spcetrograms to normalize\n",
        "  @return: the normalized spectrograms\n",
        "  '''\n",
        "\n",
        "  return_specs = []\n",
        "  for i in range(len(specs)):\n",
        "    # make a copy to ensure not changing the original spectrogram\n",
        "    cur_spec = np.copy(specs[i])\n",
        "    s_min = np.amin(cur_spec)\n",
        "    s_max = np.amax(cur_spec)\n",
        "    return_specs.append((cur_spec - s_min)/(s_max - s_min) * 255)\n",
        "\n",
        "  return return_specs"
      ],
      "outputs": [],
      "metadata": {
        "id": "8vdu4viHsDyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation Methods\n",
        "\n",
        "For each function, make a copy of the original spectrogram\n",
        "to ensure that we do not change the original one\n",
        "\n",
        "Return all the augmented spectrograms in lists for consistency"
      ],
      "metadata": {
        "id": "Divm4kJd-ufK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "def time_chop(spec, rand_start):\n",
        "  '''\n",
        "  chop the spectrogram on x axis (time) from the right\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: rand_start: the randomed index to start chopping\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  time_chopped_spec = np.copy(spec)\n",
        "  time_chopped_spec[:,224 - rand_start:,:] = 0\n",
        "\n",
        "  return [time_chopped_spec]\n",
        "\n",
        "def freq_chop(spec, rand_start):\n",
        "  '''\n",
        "  chop the spectrogram on y axis (frequency) from the top\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: rand_start: the randomed index to start chopping\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  freq_chopped_spec = np.copy(spec)\n",
        "  freq_chopped_spec[0:rand_start,:,:] = 0\n",
        "\n",
        "  return [freq_chopped_spec]\n",
        "\n",
        "def four_chop(spec, rand_start):\n",
        "  '''\n",
        "  chop the spectrogram on four sides\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: rand_start: the randomed index to start chopping\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  four_chopped_spec = np.copy(spec)\n",
        "  four_chopped_spec[0 : rand_start,:,:] = 0  # top\n",
        "  four_chopped_spec[:,224 - rand_start:,:] = 0  # right\n",
        "  four_chopped_spec[224 - rand_start:,:,:] = 0  # bottom\n",
        "  four_chopped_spec[:, 0 : rand_start ,:] = 0  # left\n",
        "\n",
        "  return [four_chopped_spec]"
      ],
      "outputs": [],
      "metadata": {
        "id": "jeHY3yeO-0FX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "def add_noises(spec):\n",
        "  '''\n",
        "  add noise to the spectrogram with 1/3 ratio\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "  # add noise from light rian -2, rain -3, heavy rain -4, thunder -5, aircraft -6, chainsaw -7, and car/truck -8\n",
        "  return_specs = []\n",
        "  noise_sonos = [-2, -3, -4, -5,-6,-7,-8]\n",
        "\n",
        "  for i in range(len(noise_sonos)):\n",
        "    noises_index = np.argwhere(sonotypes_h5 == noise_sonos[i]).flatten()\n",
        "    noises = specs_h5[noises_index]\n",
        "    # randomly pick a noise sample\n",
        "    index = random.randint(0, len(noises) - 1)\n",
        "    # normalize sound and noise, add them together with 1/3 ratio\n",
        "    noise = normalize(np.array(noises[index]) / 3)\n",
        "    return_specs.append(np.add(normalize([np.copy(spec)])[0], noise))\n",
        "\n",
        "  return return_specs"
      ],
      "outputs": [],
      "metadata": {
        "id": "2s1Hlo6q9-BC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "def translate(spec, roll_start):\n",
        "  '''\n",
        "  roll the spectrogram up and down\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: roll_start, the index to start rolling\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  return_specs = []\n",
        "  return_specs.append(np.roll(spec, -roll_start, axis = 0))\n",
        "  return_specs.append(np.roll(spec, roll_start, axis = 0))\n",
        "\n",
        "  return return_specs"
      ],
      "outputs": [],
      "metadata": {
        "id": "H3lLYDZU_VAJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "def widen(spec, widen_index):\n",
        "  '''\n",
        "  widen the spectrogram\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: widen_index, the index to decide the start and end of\n",
        "          the spectrogram to widen\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "  return_specs = []\n",
        "  widen_time_spec=cv2.resize(spec.astype('float32'),(224 + widen_index,224))\n",
        "  widen_freq_spec=cv2.resize(spec.astype('float32'),(224,224 + widen_index))\n",
        "\n",
        "  return_specs.append(widen_time_spec[:,widen_index // 2: -widen_index // 2,:])\n",
        "  return_specs.append(widen_freq_spec[widen_index // 2: -widen_index // 2,:,:])\n",
        "\n",
        "  return return_specs\n",
        "\n",
        "def squeeze(spec, squeeze_index):\n",
        "  '''\n",
        "  squeeze the spectrogram\n",
        "  @param: spec, the spectrogram to chop\n",
        "  @param: widen_index, the index to decide the start and end of\n",
        "          the spectrogram to widen\n",
        "  @return: the list of augmented spectrograms\n",
        "  '''\n",
        "\n",
        "  squeezed=cv2.resize(spec.astype('float32'),(224 - squeeze_index,224 - squeeze_index))\n",
        "  squeeze_spec = np.zeros([224, 224, 3])\n",
        "  squeeze_spec[squeeze_index//2 : - squeeze_index //2,squeeze_index//2 : - squeeze_index //2, :] = squeezed\n",
        "\n",
        "  return [squeeze_spec]"
      ],
      "outputs": [],
      "metadata": {
        "id": "QMRDhokq_Wg9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "def augment(specs, aux_input, sonotypes, aug_num, augment_range = 0.1):\n",
        "  '''\n",
        "  call all the augment methods on the spectrograms\n",
        "\n",
        "  @param: specs is the list of spectrograms to augment from\n",
        "  @param: aux_input is the list of auxiliary input corresponds to the spectrograms\n",
        "  @param: sonotypes is the list of sonnotypes corresponds to the spectrograms\n",
        "  @param: aug_num is the number of sets of augmented spectrograms\n",
        "          (returned number of samples will be 1 + 15*aug_num)\n",
        "  @param: augment_range is the threshold used for augmentations, default to 0.1\n",
        "  @return: augment_specs_func is the list of augmented spectrograms\n",
        "  @return: augment_aux_func is the list of  auxiliary input corresponds to the spectrograms\n",
        "  @return: augment_sono_func is the list of sonotypes input corresponds to the spectrograms\n",
        "  '''\n",
        "\n",
        "  augment_specs_func = []\n",
        "  augment_aux_func = []\n",
        "  augment_sono_func = []\n",
        "\n",
        "  # print(len(aux_input))\n",
        "  for i in range(len(specs)):\n",
        "    # generate random index array for augmentation\n",
        "    # in 5% to 10% of the size of the original spectrogram\n",
        "    # 224 * 224 is the image size\n",
        "    indices = np.arange(int(224 * augment_range / 3 * 2) , int(224 * augment_range))\n",
        "    np.random.shuffle(indices)\n",
        "    indices = indices[:aug_num]\n",
        "\n",
        "    # augment each spec and add to list\n",
        "    cur_spec = np.copy(specs[i])\n",
        "    # add itself to the list\n",
        "    if (len(augment_specs_func)):\n",
        "      augment_specs_func = np.append(augment_specs_func, [cur_spec], axis = 0)\n",
        "    else:\n",
        "      augment_specs_func.append(cur_spec)\n",
        "    # augment_specs_func.append(cur_spec)\n",
        "\n",
        "    for index in indices:\n",
        "      # print(index)\n",
        "      # chop\n",
        "      augment_specs_func = np.append(augment_specs_func, time_chop( np.copy(cur_spec), index), axis = 0)\n",
        "      augment_specs_func = np.append(augment_specs_func, freq_chop( np.copy(cur_spec), index), axis = 0)\n",
        "      augment_specs_func = np.append(augment_specs_func, four_chop( np.copy(cur_spec), index), axis = 0)\n",
        "\n",
        "      # widen + squeeze\n",
        "      augment_specs_func = np.append(augment_specs_func, squeeze( np.copy(cur_spec), index), axis = 0)\n",
        "      augment_specs_func = np.append(augment_specs_func, widen( np.copy(cur_spec), index), axis = 0)\n",
        "\n",
        "      # noise\n",
        "      augment_specs_func = np.append(augment_specs_func, add_noises(np.copy(cur_spec)), axis = 0)\n",
        "\n",
        "      # translate\n",
        "      augment_specs_func = np.append(augment_specs_func, translate(np.copy(cur_spec), index), axis = 0)\n",
        "\n",
        "    # total 1 + 15 * aug_num augmented, repeat the sono and aux\n",
        "    if (len(augment_aux_func)):\n",
        "      augment_aux_func = np.append(augment_aux_func, np.repeat([aux_input[i]], 1 + 15 * aug_num, axis = 0), axis= 0)\n",
        "    else:\n",
        "      augment_aux_func = np.repeat([aux_input[i]], 1 + 15 * aug_num, axis = 0)\n",
        "\n",
        "    augment_sono_func = np.append(augment_sono_func, np.repeat(sonotypes[i], 1 + 15 * aug_num), axis= 0)\n",
        "\n",
        "  return augment_specs_func, augment_aux_func, augment_sono_func"
      ],
      "outputs": [],
      "metadata": {
        "id": "XfJQnb19kqGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model and Training"
      ],
      "metadata": {
        "id": "cHlMGXpZBET4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "config = dict(\n",
        "    dropout = 0.5,\n",
        "    hidden = 1024,\n",
        "    learn_rate = 0.00001,\n",
        "    epochs = 30,\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "tmpT97hABD3x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "def build_finetune_model(base_model, dropouts, fc_layers, num_classes):\n",
        "    '''\n",
        "    finetune the model, freeze teh top layers,\n",
        "    add dropouts, dense layers,\n",
        "    another input layer for auxiliary input\n",
        "    and concatenate it with the flatten layer\n",
        "    '''\n",
        "\n",
        "    # freeze the base layers\n",
        "    for layer in base_model.layers:\n",
        "       layer.trainable = False\n",
        "\n",
        "    # add flatten layer\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # add input layer for auxiliary input (time and frequency)\n",
        "    auxiliary_input = Input(shape=(4,), name='aux_input')\n",
        "    x = concatenate([x, auxiliary_input])\n",
        "\n",
        "    #  dense and dropout layer\n",
        "    for fc, drop in zip(fc_layers, dropouts):\n",
        "        x = Dense(fc, activation='relu')(x)\n",
        "        x = Dropout(drop)(x)\n",
        "\n",
        "    # final dense layer for output\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    finetune_model = Model(inputs=[base_model.input,auxiliary_input], outputs=predictions)\n",
        "\n",
        "    return finetune_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "89CFyhKcBHgW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "class TestCallback(keras.callbacks.Callback):\n",
        "    '''\n",
        "    The class used to see the test result during training\n",
        "    '''\n",
        "\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        x, y = self.test_data\n",
        "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
        "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
      ],
      "outputs": [],
      "metadata": {
        "id": "6id17t85n_3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "def gen(specs, aux_input, sonotypes):\n",
        "  '''\n",
        "  generator functiion for fit_generator\n",
        "  augment the samples and yield the augmented samples to train the model\n",
        "\n",
        "  As the data would be too large if we augment all the images before training,\n",
        "  we need to use this function to augment the images during the training process\n",
        "\n",
        "  @param: specs, the list of spectrograms\n",
        "  @param: aux_input, the list of auxiliary input corresponding to the spectrograms\n",
        "  @param: sonotypes, the list of sonotypes corresponding to the spectrograms\n",
        "  '''\n",
        "\n",
        "  # augment_specs, augment_aux, augment_sono =  augment(specs_seperated[i], aux_seperated[i], sono_seperated[i], 1)\n",
        "  while 1:\n",
        "    # shuffle data\n",
        "    indices = np.arange(len(sonotypes))\n",
        "    np.random.shuffle(indices)\n",
        "    # augment 4 samples to get 64 samples per yield (suitable for training)\n",
        "    step_len = 4\n",
        "\n",
        "    for i in range(len(specs) // step_len):\n",
        "      step_min = i * step_len\n",
        "      step_max = min( (i + 1) * step_len, len(specs) )\n",
        "\n",
        "      augment_specs, augment_aux, augment_sono =  augment(specs[indices][step_min: step_max], aux_input[indices][step_min: step_max], sonotypes[indices][step_min: step_max], 1)\n",
        "\n",
        "      # normalize spectrograms and categorical outputs\n",
        "      augment_specs_normal = normalize(augment_specs)\n",
        "      cat_y_train = to_categorical(augment_sono, num_classes= len(typeUsed))\n",
        "\n",
        "      yield {'input_1': np.array([augment_specs_normal])[0], 'aux_input': np.array([augment_aux])[0]}, np.array([cat_y_train])[0]"
      ],
      "outputs": [],
      "metadata": {
        "id": "-wPPQ60_rctY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "model = None\n",
        "keras.backend.clear_session()\n",
        "# get the pretrained model\n",
        "model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "# finetune to our case\n",
        "model = build_finetune_model(model,\n",
        "                             [config[\"dropout\"], config[\"dropout\"]],\n",
        "                             [config[\"hidden\"], config[\"hidden\"]],\n",
        "                             len(typeUsed))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "metadata": {
        "id": "9r8uQ7upBJBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e4ade9-3500-413c-e99f-6ad8d6ca5a5e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# # model stats, remove \"#\" in lines below to print\n",
        "# model.summary()\n",
        "# plot_model(model,to_file = 'My Drive/CNN-example/model.png')"
      ],
      "outputs": [],
      "metadata": {
        "id": "wvacKNbVBOTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# we need to reset the model when starting a new training process, can be done with codes below\n",
        "# (the same as in one of the above cells, just copy here for easier use)\n",
        "\n",
        "# model = None\n",
        "# keras.backend.clear_session()\n",
        "# # get the pretrained model\n",
        "# model = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "# # finetune to our case\n",
        "# model = build_finetune_model(model,\n",
        "#                              [config[\"dropout\"], config[\"dropout\"]],\n",
        "#                              [config[\"hidden\"], config[\"hidden\"]],\n",
        "#                              len(typeUsed))\n",
        "\n",
        "# training\n",
        "filepath_loss = 'My Drive/CNN-example/model_loss.hdf5'\n",
        "\n",
        "# remove model before\n",
        "if os.path.exists(filepath_loss):\n",
        "  os.remove(filepath_loss)\n",
        "\n",
        "# early stopping and checkpoint to save the model with the lowest validation\n",
        "earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "checkpoint = ModelCheckpoint(filepath_loss, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "# optimization method for training\n",
        "opt = Adam(learning_rate=config[\"learn_rate\"])\n",
        "\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# if we want to see the test result along the training, add \"TestCallback((x_test, cat_y_test))\" to callbacks\n",
        "# i.e. callbacks=[checkpoint_loss, checkpoint_acc, TestCallback((x_test, cat_y_test))]\n",
        "\n",
        "# with augmentation\n",
        "history = model.fit(gen(specs, aux_input, sonotypes),\n",
        "                    steps_per_epoch=len(specs) // 4, epochs = 300, validation_data = (x_val, cat_y_val), callbacks=[checkpoint, earlystop])\n",
        "\n",
        "# without augmentation\n",
        "# cat_y_train = to_categorical(sonotypes, num_classes=len(typeUsed))\n",
        "# history = model.fit(x=[specs, aux_input], y=cat_y_train, validation_data=(x_val, cat_y_val), epochs=300, verbose=2, callbacks=[checkpoint, earlystop])"
      ],
      "outputs": [],
      "metadata": {
        "id": "X1vd2PGgjfHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452f7830-52c3-42c8-b310-44e12b8e7ec9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Evaluate the model\n",
        "# current model\n",
        "results = model.evaluate( x= x_test, y=cat_y_test)\n",
        "print(\"cur test loss, test acc:\", results)\n",
        "\n",
        "# The model with best loss\n",
        "# load the model\n",
        "model = None\n",
        "keras.backend.clear_session()\n",
        "model = load_model (filepath_loss)\n",
        "\n",
        "# evaluate\n",
        "results = model.evaluate( x= x_test, y=cat_y_test)\n",
        "\n",
        "print(\"best loss test loss, test acc:\", results)"
      ],
      "outputs": [],
      "metadata": {
        "id": "p113jhUijjfI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ROC/AUC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_score = model.predict(x_test)\n",
        "y_class = [typeUsed[i]\n",
        "            for i in np.argmax(y_score, axis=1)]  # predicted class\n",
        "y_true = [typeUsed[i] for i in y_test]  # true class\n",
        "roc_score = roc_auc_score(\n",
        "    y_test, y_score, sample_weight=None, multi_class=\"ovo\")\n",
        "\n",
        "print(roc_score)"
      ],
      "outputs": [],
      "metadata": {
        "id": "x3oCdHJ_BWJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# precision, recall, f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_predict_index = np.argmax(y_score, axis=1)\n",
        "\n",
        "precision = precision_score(y_test, y_predict_index, average=\"macro\")\n",
        "recall = recall_score(y_test, y_predict_index, average=\"macro\")\n",
        "f1 = f1_score(y_test, y_predict_index, average=\"macro\")\n",
        "\n",
        "print(\"precision:\", precision)\n",
        "print(\"recall:\", recall)\n",
        "print(\"f1 score:\", f1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OxLNTD3UBWJ2"
      }
    }
  ]
}