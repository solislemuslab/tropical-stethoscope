{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sample_dataset_creation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyNh+Epvv4bixFA3jHfFbDn/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"S_tNTV43KaGW","executionInfo":{"status":"ok","timestamp":1624217731575,"user_tz":300,"elapsed":1625,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}}},"source":["# import the dependencies\n","import numpy as np\n","import scipy\n","import soundfile as sf\n","import csv\n","import h5py\n","import cv2"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Lgabz37Kd61","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624217772981,"user_tz":300,"elapsed":6721,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}},"outputId":"22464814-7774-4fb7-c22b-1539b5ac0de3"},"source":["# if use google colab, run the following lines\n","from google.colab import drive\n","import os\n","# google colab might not have soundfile package installed in the enviroment\n","# if this happends, run the following line to install it\n","# !pip install soundfile\n","\n","# give colab the right to access your file\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vgw-KnZrO29e"},"source":["# Parse the label file <br>\n","\n","This is our approach to parse the label file. It is not necessary to do it in this way and the approach is based on how people store data in the label file. \n","\n","The main idea is to retrieve all the info to plot and chop the spectrogram, including path to the wav file, the start and end time, minimum and maximum frequency, sonotype, and taxonomic group for each label"]},{"cell_type":"code","metadata":{"id":"nSQOd48XO0YZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624219557957,"user_tz":300,"elapsed":141,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}},"outputId":"b7de5bd9-f24e-4be4-847c-5954911f484f"},"source":["# path to the label file\n","labelDir = \"My Drive/Stethoscope/\" # path to the folder storing label files\n","labelFile = \"sample_labels.txt\" # label file name\n","soundDir = \"My Drive/Stethoscope/\" # path to the folder storing wav files\n","\n","# lists to store data\n","times = [] # times in the wav file\n","freqs = []\n","files = []\n","sonotypes = []\n","actTimes = [] # time of the day\n","groups = [] # taxonomic group\n","selection = [] # this is not required and only used to trace the labels\n","\n","labelFilePath = labelDir + labelFile \n","with open(labelFilePath) as file:\n","  # read file, info in each row is separated by tabs\n","  label_reader = csv.reader(file, delimiter='\\t')\n","  \n","  for row in label_reader:\n","    # not use the first row: first row contains attributes\n","    # other rows should start with the selection number\n","    if (not row[0].isnumeric()):\n","      continue\n","\n","    # in our label file, the begin and end time are not related \n","    # to the actual position in the sound file, \n","    # so we only use those info to retrieve duration of the sounds\n","    duration = float(row[4]) - float(row[3])\n","    \n","    # use the Delta Time to retrieve the actural start time\n","    # and convert to seconds in the day\n","    timeWeight = [3600,60,1,0.0001]\n","    actSta = sum([a*b for a,b in zip(timeWeight, map(int,row[10].replace('.',\":\").split(':')))])\n","    \n","    # use the duration to retrieve the end time in secons in the day\n","    actEnd = actSta + duration \n","    \n","    # get file name for the labels\n","    fileName = soundDir + row[7].split(\"\\\\\")[-1]\n","\n","    # get the start time of wav file \n","    # we store the start time of wav file in its name\n","    # to get the corresponding start time of the label\n","    # actual time is either in index 1 or 2 in splName\n","    splName = row[7].split(\"\\\\\")[-1].split(\"_\")\n","    strTime = splName[1]         \n","    # conver to seconds of the day\n","    recLis = [int(strTime[0]) * 10 + int(strTime[1]),\n","              int(strTime[2]) * 10 + int(strTime[3]), \n","              int(strTime[4]) * 10 + int(strTime[5])]    \n","    recSta = sum([a*b for a,b in zip(timeWeight, recLis)])\n","\n","    # start, end time used to corp the specs\n","    start = actSta - recSta\n","    end = start + duration\n","\n","    try:\n","      sonotypes.append(int(row[11]))\n","      times.append([start,end])\n","      actTimes.append([actSta, actEnd])\n","      freqs.append([float(row[5]), float(row[6])])\n","      files.append(fileName) \n","      groups.append(row[12])\n","      selection.append(int(row[0]))\n","    except:\n","      # exception: print file and selection number\n","      print(filename)\n","      print(row[0])\n","      pass\n","\n","    # uncomment the following lines to print data related to this label\n","    # print(\"filename: %s\" % (fileName))\n","    # print(\"Start time: %f, End time: %f\" % (start, end))\n","    # print(\"Actual Start time: %f, Actual End time: %f\" % (actSta, actEnd))\n","    # print(\"minimum frequency: %f, maximum frequency: %f \\n\" % (float(row[5]), float(row[6])))\n","\n","# some stats\n","print(\"dataset size:  %i\" % len(times))    \n","print(\"filename sample: \" + files[0])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["dataset size:  35\n","filename sample: My Drive/Stethoscope/20180908_060000_13A_24H.wav\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YY5COntfgOSW"},"source":["#Creat H5 data storage\n"]},{"cell_type":"code","metadata":{"id":"Vj3bjckjgRrK","executionInfo":{"status":"ok","timestamp":1624219605168,"user_tz":300,"elapsed":134,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}}},"source":["h5Path = 'My Drive/Stethoscope/sample_data.hdf5'\n","f = h5py.File(h5Path, 'w')\n","\n","data = f.create_dataset(\"specs\", (0,224,224,3,), maxshape=(None,None,None,None,), chunks=True)\n","data = f.create_dataset(\"sonotypes\", (0,),  maxshape=(None,), chunks=True)\n","data = f.create_dataset(\"times\", (0,2,), maxshape=(None,None,), chunks=True)\n","data = f.create_dataset(\"freqs\", (0,2,), maxshape=(None,None,), chunks=True)\n","data = f.create_dataset(\"groups\", (0,),  maxshape=(None,), chunks=True, dtype=\"S10\")\n","data = f.create_dataset(\"selections\", (0,),  maxshape=(None,), chunks=True)\n","\n","f.close()"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SiNlNSgGGK7s"},"source":["# Get the data according to the labels and store into database\n"]},{"cell_type":"code","metadata":{"id":"-M1l-rrCOr-9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624220215777,"user_tz":300,"elapsed":6481,"user":{"displayName":"YUREN SUN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gij_u8dz_gjnTlGMTY6-5CE94S6R4yHlxYjbV0vTQ=s64","userId":"11675060901325192603"}},"outputId":"a9855d05-2c80-431f-9ba3-ee58839834bb"},"source":["# path to all the sound files\n","fileDirPath = \"\"\n","# fileDirNames = [\"13AB/\", \"Control sites/\"]\n","\n","# all the files contained in the label file\n","# In the sample, we only have one file\n","usedFiles = np.unique(files)\n","# print(usedFiles)\n","\n","for curFile in usedFiles:\n","  print(\"Processing \" + curFile)\n","  \n","  filePath = fileDirPath + curFile\n","  \n","  # read the wav file\n","  try:\n","    audio, rate = sf.read(filePath)\n","  except:\n","    print(\"ERROR READING FILE\")\n","    continue\n","\n","  # used to store info after resizing the image\n","  specs_resized = []\n","  freqs_updated = []\n","  times_updated = []\n","  sonotypes_updated = []\n","  groups_updated = []\n","  selections_updated = []\n","\n","  # plot the spectrogram\n","  # default setting of scipy, tukey window and 0.25 for shape parameter\n","  freq, t, spec = scipy.signal.spectrogram(audio, rate)\n","\n","  # An alternative is using the plt spectrogram, but we do not use this\n","  # spec,freq, t,im = plt.specgram(audio,Fs=rate)\n","  # im = None\n","  # plt.clf() # clean the plt backend to clear up ram\n","\n","  for i in range(len(files)):\n","    # chop the labels for cur wav file\n","    if(files[i] == curFile):\n","      # label time and frequency\n","      boxTime = times[i]\n","      boxFreq = freqs[i]\n","\n","      # get low and high freq index of the box\n","      low_freq = np.argmin(np.abs(freq - boxFreq[0]))\n","      high_freq = np.argmin(np.abs(freq - boxFreq[1]))\n","      # get s tart and end time of the box\n","      start = np.argmin(np.abs(t - boxTime[0]))\n","      end = np.argmin(np.abs(t - boxTime[1]))\n","\n","      # adjust the params to cover the whole box\n","      # be aware of index out of bound\n","      if freq[low_freq] > boxFreq[0]: \n","        low_freq = max(low_freq -1,0)\n","      if freq[high_freq] < boxFreq[1]: \n","        high_freq = high_freq + 1\n","      if t[start] > boxTime[0]: \n","        start = max(start - 1, 0)\n","      if t[end] < boxTime[1]: \n","        start = start + 1\n","\n","      # make a copy to not alter the original spectrogram\n","      cur_spec = np.copy(spec)[low_freq:high_freq, start:end]\n","\n","      # resize the image to 224*224*3\n","      if cur_spec.size != 0: # just in case\n","        # resize\n","        spec_resized = cv2.resize(cur_spec.astype('float32'),(224,224))\n","        spec_resized = np.expand_dims(spec_resized, 2)\n","        spec_resized = np.flip(spec_resized,0)\n","       \n","        # put to the list to add to h5df \n","        specs_resized.append(spec_resized)\n","        freqs_updated.append(freqs[i])\n","        times_updated.append(actTimes[i])\n","        sonotypes_updated.append(sonotypes[i])\n","        groups_updated.append(groups[i]) \n","        selections_updated.append(selection[i]) \n","  \n","  # store to H5 data storage\n","  if len(specs_resized) != 0:\n","    f =  h5py.File(h5Path, \"a\")\n","    # here we use length of time_update for all the lengh used \n","    # to resize and alter the h5df as the lenght of all the lists that we use \n","    # are the same\n","    \n","    f[\"times\"].resize((f[\"times\"].shape[0] + len(times_updated)), axis = 0)\n","    f[\"times\"][-len(times_updated):,:] = times_updated\n","\n","    f[\"freqs\"].resize((f[\"freqs\"].shape[0] +  len(times_updated)), axis = 0)\n","    f[\"freqs\"][-len(times_updated):,:] = freqs_updated\n","\n","    f[\"specs\"].resize((f[\"specs\"].shape[0] +  len(times_updated)), axis = 0)\n","    f[\"specs\"][-len(times_updated):,:,:,:] = specs_resized\n","\n","    f[\"sonotypes\"].resize((f[\"sonotypes\"].shape[0] + len(times_updated)), axis = 0)\n","    f[\"sonotypes\"][-len(times_updated):] = np.array(sonotypes_updated)\n","\n","    f[\"groups\"].resize((f[\"groups\"].shape[0] + len(times_updated)), axis = 0)\n","    f[\"groups\"][-len(times_updated):] = np.array(groups_updated, dtype=\"S\")\n","\n","    f[\"selections\"].resize((f[\"selections\"].shape[0] + len(times_updated)), axis = 0)\n","    f[\"selections\"][-len(times_updated):] = np.array(selections_updated)\n","\n","    f.close()\n","  else:\n","    # no spectrogram found for cur file, should be an exception\n","    # just print out the name\n","    print(\"No label found: \", curFile)\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Processing My Drive/Stethoscope/20180908_060000_13A_24H.wav\n"],"name":"stdout"}]}]}